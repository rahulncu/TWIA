{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWIA Lab Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Split: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog.']\n",
      "After Token: [('the', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog.', 'NN')]\n",
      "After Regex: chunk.RegexpParser with 1 stages:\n",
      "RegexpChunkParser with 1 rules:\n",
      "       <ChunkRule: '<NN.?>*<VBD.?>*<JJ.?>*<CC>?'>\n",
      "After Chunking (S\n",
      "  the/DT\n",
      "  (mychunk quick/JJ)\n",
      "  (mychunk brown/NN fox/NN)\n",
      "  jumps/VBZ\n",
      "  over/IN\n",
      "  the/DT\n",
      "  (mychunk lazy/JJ)\n",
      "  (mychunk dog./NN))\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "text =\"the quick brown fox jumps over the lazy dog.\".split()\n",
    "print(\"After Split:\",text)\n",
    "text_tag = pos_tag(text)\n",
    "print(\"After Token:\",text_tag)\n",
    "paterns= \"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
    "chunk = RegexpParser(paterns)\n",
    "print(\"After Regex:\",chunk)\n",
    "output = chunk.parse(text_tag)\n",
    "print(\"After Chunking\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'very', 'efficient', 'mother', 'just', 'served', 'us', 'nuts']\n",
      "[('My', 'PRP$'), ('very', 'RB'), ('efficient', 'JJ'), ('mother', 'NN'), ('just', 'RB'), ('served', 'VBD'), ('us', 'PRP'), ('nuts', 'NNS')]\n",
      "(S\n",
      "  My/PRP$\n",
      "  very/RB\n",
      "  (NP efficient/JJ mother/NN)\n",
      "  just/RB\n",
      "  served/VBD\n",
      "  us/PRP\n",
      "  nuts/NNS)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text1 = \"My very efficient mother just served us nuts\"\n",
    "text_token = nltk.word_tokenize(text1)\n",
    "print(text_token)\n",
    "textag = nltk.pos_tag(text_token)\n",
    "print(textag)\n",
    "grammer = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "textreg  =nltk.RegexpParser(grammer)\n",
    "text_parse = textreg.parse(textag)\n",
    "print(text_parse)\n",
    "text_parse.draw()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP\n",
      "    The/DT\n",
      "    small/JJ\n",
      "    red/JJ\n",
      "    flower/NN\n",
      "    flew/VBD\n",
      "    through/IN\n",
      "    the/DT\n",
      "    window/NN))\n"
     ]
    }
   ],
   "source": [
    "text = [(\"The\", \"DT\"), (\"small\", \"JJ\"), (\"red\", \"JJ\"),(\"flower\", \"NN\"), (\"flew\", \"VBD\"), (\"through\", \"IN\"),  (\"the\", \"DT\"), (\"window\", \"NN\")]\n",
    "\n",
    "grammer = r\"\"\"\n",
    "  NP:\n",
    "    {<.*>+}         \n",
    "  \"\"\"\n",
    "chunk_reg = nltk.RegexpParser(grammer)\n",
    "chunk_pars = chunk_reg.parse(text) \n",
    "print(chunk_pars)\n",
    "chunk_pars.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('wake', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('string', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('abuses', 'NNS'),\n",
       " ('by', 'IN'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('police', 'NN'),\n",
       " ('officers', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('1990s', 'CD'),\n",
       " (',', ','),\n",
       " ('Loretta', 'NNP'),\n",
       " ('E.', 'NNP'),\n",
       " ('Lynch', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('top', 'JJ'),\n",
       " ('federal', 'JJ'),\n",
       " ('prosecutor', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Brooklyn', 'NNP'),\n",
       " (',', ','),\n",
       " ('spoke', 'VBD'),\n",
       " ('forcefully', 'RB'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pain', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('broken', 'JJ'),\n",
       " ('trust', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('African-Americans', 'NNP'),\n",
       " ('felt', 'VBD'),\n",
       " ('and', 'CC'),\n",
       " ('said', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('responsibility', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('repairing', 'VBG'),\n",
       " ('generations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('miscommunication', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('mistrust', 'NN'),\n",
       " ('fell', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('law', 'NN'),\n",
       " ('enforcement', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "eg = \"In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\"\n",
    "eg_token = nltk.word_tokenize(eg)\n",
    "eg_pos = nltk.pos_tag(eg_token)\n",
    "eg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
